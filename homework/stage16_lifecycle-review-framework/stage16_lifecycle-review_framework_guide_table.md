# Applied Financial Engineering — Framework Guide Template

This Framework Guide is a structured reflection tool.  
Fill it in as you progress through the course or at the end of your project.  
It will help you connect each stage of the **Applied Financial Engineering Lifecycle** to your own project, and create a portfolio-ready artifact.

---

## How to Use

- Each row corresponds to one stage in the lifecycle.
- Use the prompts to guide your answers.
- Be concise but specific — 2–4 sentences per cell is often enough.
- This is **not a test prep sheet**. It’s a way to _document, reflect, and demonstrate_ your process.

---

## Framework Guide Table

| Lifecycle Stage                                                        | What You Did                                                                                                                                                                                                                     | Challenges                                                                                                                             | Solutions / Decisions                                                                                                                                                                                    | Future Improvements                                                                                                                                            |
| ---------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **1. Problem Framing & Scoping**                                       | Create a Credit Card Fraud Detection classifier. Assumed real dataset as best data option, and the constraints were limited feature creation due to PCA.                                                                         | PCA and class imbalance made determining metrics difficult                                                                             | This was done on a case by case basis, after trianing finished and understanding limitations of data. Due to the model being classification, Recall >90% was used, and PR-AUC was also used for analysis | Do more research into anonymized datasets with less PCA for better understanding                                                                               |
| **2. Tooling Setup**                                                   | I used requirements.txt (pip) initially, but conda worked better so that was used. Data Analysis and ML tools were installed on a step by step basis.                                                                            | There was an issue with pip not qorking correctly, which causes the switch to conda                                                    | I just switched to conda and made sure it worked when I ran.                                                                                                                                             | I would automate the setup with a script that uses the conda environment.yml to make the environment automatically, and install packages                       |
| **3. Python Fundamentals**                                             | I used general Python syntax and functions, with pakcages like pandas and numpy for manipulation/analysis. Seaborn and matplotlib were used for visualization later and scikit-learn for ML.                                     | I was pretty familiar with some of thses so it wasn't an issue.                                                                        | I just used practice and online tutorials, and GPT to explain functions                                                                                                                                  | I think just learning more and more functions is the best skill I could start to work on so I don't have to learn them on new projects or in classe            |
| **4. Data Acquisition / Ingestion**                                    | My data came from a Kaggle API, which was open source and didn't require a key or anything                                                                                                                                       | There wer none at all, especially considering the data quality                                                                         | For both the syntehetic data and project data, I used csvs which werew the easiest qay to format the data                                                                                                | I would improve the automation of the timestamping and the gitignore because these files shouldn't be pushed to remote, especially if it had real info         |
| **5. Data Storage**                                                    | I stored my data in data/                                                                                                                                                                                                        | There weren't any problems with the format, I just had to install a parquet package                                                    | I used the homeworks timestamping, which is good for data versioning and identification if the datset changes                                                                                            | More specific folders for each format, would be better if it was automated                                                                                     |
| **6. Data Preprocessing**                                              | I ran winsorization and IQR filtering, and I found that it wasn't very helpful, along with there being no data missing                                                                                                           | There weren't difficulties any so this was fine                                                                                        | I decided against them due to the fact that the data quality were good, with the metrics being along the same lines                                                                                      | Have a list of features to use from time to analyze in the correlation matrix and research other time based features                                           |
| **7. Outlier Analysis**                                                | In this case, I decided not to remove data because the data was all legitimate and no NaNs were present                                                                                                                          | The lack of error meant that this wasn't an issue                                                                                      | Did not drop any outliers because the model is especially sensitive to them and a lack of outliers would make it fail to detect large fraud                                                              | If the other columns were available without PCA I would do outlier analysis per column to better see where the outliers are                                    |
| **8. Exploratory Data Analysis (EDA)**                                 | Utilized Correlation Matrices, Distribution plots, confusion matrices, and outlier analysis plots for each V\_ feature                                                                                                           | The PCA lead to unknown but useful columns, so further understanding was difficult                                                     | Researched about the distribution types for credit card fraud and also used general knowledge to explain between correlation matrices versus outlier plots                                               | Knowing the columns themselves would greatly help with understand the V\_ columns and how they interact with the rest of the data                              |
| **9. Feature Engineering**                                             | There wasn't much feature engineering due to PCA already being done but some minute and hour grouping based features were made, though it didn't look to help much                                                               | The time based features were difficult because the time range was so small anad they weren't already formatted in data teim            | I used the Correlation Matrix, and also the fact that the best features were probably in PCA, so they should all be used for the first runs                                                              | I could add time since last fraud because that can help group fraud cases together if they are spread apart or close together                                  |
| **10. Modeling (Regression / Time Series / Classification)**           | The only model tried was classification due to it being the best for this data. A larger dataset would have allowed for time based features for better analysis                                                                  | There is definitely an issue with underfitting due to poor F1 score and Recall in the first run                                        | I chose the model of classification because it is the only one that makes sense out of the three. Tuned with multiple preprocessing scenarios.                                                           | Try ensemble methods and other types like trees (random, decision)                                                                                             |
| **11. Evaluation & Risk Communication**                                | Confidence Intervals were used, and the F1 and PR scores were used to see how well the classification model was working                                                                                                          | Assuming bootstrapping would help was an issue because the binary classification did not work well; only the zeroes were being covered | I used simple explanations with generous images to make sure that stakeholders could undestand easily                                                                                                    | I would also add evaluation steps for data drift so any data changes can be monitored and alerted                                                              |
| **12. Results Reporting, Delivery Design & Stakeholder Communication** | I used a markdown file to show the results, with images for metrics and anlaysis                                                                                                                                                 | Some of the pitfalls of the model were difficult, and also putting it in a neat format instead of a notebook of metrics                | Keeping it simple was the plan so there wasn't much technical and other filler stuff to confuse stakeholders                                                                                             | I would explain some things better with images so that makes more sense for stakeholders, along with a front end so model metrics are seen nicely in real time |
| **13. Productization**                                                 | I leveraged the repository structure and other utility functions to make it easier to implement once I got the notebook end to end structure down                                                                                | There was an issue with Flask not running in terminal, but that was fixed and no further issues arised                                 | I had good fallbacks and cleaer error reporting to make sure that the run didn't have any complications and allowed for adjustment                                                                       | I would create an actual CI/CD pipeline so the endpoint is always online and better responsive to changes                                                      |
| **14. Deployment & Monitoring**                                        | Used Flask in app.py                                                                                                                                                                                                             | Balancing Automation with human in the loop was difficult, along with my inexperience with production monitoring                       | I used checkpoints for system benchmarking and also some simple thresholds based on business logic                                                                                                       | I would add an actual dashboard so I don't have to check specific APIs or files                                                                                |
| **15. Orchestration & System Design**                                  | I just isolated biggest areas and then in those what are some pain points or big todos                                                                                                                                           | Understanding that a step could have two dependencies, which made ordering easier                                                      | I thought about the biggest non separable parts of the process and also had multi acylic dependencies for better ordering                                                                                | I would learn airflow to better undderstand the system design with visuals                                                                                     |
| **16. Lifecycle Review & Reflection**                                  | I think understanding all the steps is essential for an effective project. Focusing on the technical or the stakeholder report is not going to be enough to properly have an effective mofel and convey to the stakeholders well | The non technical deliverables were more difficult                                                                                     | Iterative development and clear documentation helped me understand as I was going back and forth                                                                                                         | I would do more planning ahead as some stages, like training, depend on previous features                                                                      |

---

## Reflection Prompts

- Which stage was the most **difficult** for you, and why?
- Which stage was the most **rewarding**?
- How do the stages **connect** — where did one stage’s decisions constrain or enable later stages?
- If you repeated this project, what would you **do differently across the lifecycle**?
- Which skills do you most want to **strengthen** before your next financial engineering project?

---
